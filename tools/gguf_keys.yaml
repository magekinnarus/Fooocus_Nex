Tensors Found: 1680
------------------------------
Key: input_blocks.0.0.bias                                        | Type: F16 | Shape: [320]
Key: input_blocks.0.0.weight                                      | Type: F16 | Shape: [256  45]
Key: input_blocks.1.0.emb_layers.1.bias                           | Type: F16 | Shape: [320]
Key: input_blocks.1.0.emb_layers.1.weight                         | Type: Q8_0 | Shape: [1280  320]
Key: input_blocks.1.0.in_layers.0.bias                            | Type: F16 | Shape: [320]
Key: input_blocks.1.0.in_layers.0.weight                          | Type: F16 | Shape: [320]
Key: input_blocks.1.0.in_layers.2.bias                            | Type: F16 | Shape: [320]
Key: input_blocks.1.0.in_layers.2.weight                          | Type: Q8_0 | Shape: [ 256 3600]
Key: input_blocks.1.0.out_layers.0.bias                           | Type: F16 | Shape: [320]
Key: input_blocks.1.0.out_layers.0.weight                         | Type: F16 | Shape: [320]
Key: input_blocks.1.0.out_layers.3.bias                           | Type: F16 | Shape: [320]
Key: input_blocks.1.0.out_layers.3.weight                         | Type: Q8_0 | Shape: [ 256 3600]
Key: input_blocks.2.0.emb_layers.1.bias                           | Type: F16 | Shape: [320]
Key: input_blocks.2.0.emb_layers.1.weight                         | Type: Q8_0 | Shape: [1280  320]
Key: input_blocks.2.0.in_layers.0.bias                            | Type: F16 | Shape: [320]
Key: input_blocks.2.0.in_layers.0.weight                          | Type: F16 | Shape: [320]
Key: input_blocks.2.0.in_layers.2.bias                            | Type: F16 | Shape: [320]
Key: input_blocks.2.0.in_layers.2.weight                          | Type: Q8_0 | Shape: [ 256 3600]
Key: input_blocks.2.0.out_layers.0.bias                           | Type: F16 | Shape: [320]
Key: input_blocks.2.0.out_layers.0.weight                         | Type: F16 | Shape: [320]
Key: input_blocks.2.0.out_layers.3.bias                           | Type: F16 | Shape: [320]
Key: input_blocks.2.0.out_layers.3.weight                         | Type: Q8_0 | Shape: [ 256 3600]
Key: input_blocks.3.0.op.bias                                     | Type: F16 | Shape: [320]
Key: input_blocks.3.0.op.weight                                   | Type: Q8_0 | Shape: [ 256 3600]
## the middle layers are deleted for brevity
Key: output_blocks.7.0.emb_layers.1.bias                          | Type: F16 | Shape: [320]
Key: output_blocks.7.0.emb_layers.1.weight                        | Type: Q8_0 | Shape: [1280  320]
Key: output_blocks.7.0.in_layers.0.bias                           | Type: F16 | Shape: [640]
Key: output_blocks.7.0.in_layers.0.weight                         | Type: F16 | Shape: [640]
Key: output_blocks.7.0.in_layers.2.bias                           | Type: F16 | Shape: [320]
Key: output_blocks.7.0.in_layers.2.weight                         | Type: Q8_0 | Shape: [ 256 7200]
Key: output_blocks.7.0.out_layers.0.bias                          | Type: F16 | Shape: [320]
Key: output_blocks.7.0.out_layers.0.weight                        | Type: F16 | Shape: [320]
Key: output_blocks.7.0.out_layers.3.bias                          | Type: F16 | Shape: [320]
Key: output_blocks.7.0.out_layers.3.weight                        | Type: Q8_0 | Shape: [ 256 3600]
Key: output_blocks.7.0.skip_connection.bias                       | Type: F16 | Shape: [320]
Key: output_blocks.7.0.skip_connection.weight                     | Type: Q8_0 | Shape: [256 800]
Key: output_blocks.8.0.emb_layers.1.bias                          | Type: F16 | Shape: [320]
Key: output_blocks.8.0.emb_layers.1.weight                        | Type: Q8_0 | Shape: [1280  320]
Key: output_blocks.8.0.in_layers.0.bias                           | Type: F16 | Shape: [640]
Key: output_blocks.8.0.in_layers.0.weight                         | Type: F16 | Shape: [640]
Key: output_blocks.8.0.in_layers.2.bias                           | Type: F16 | Shape: [320]
Key: output_blocks.8.0.in_layers.2.weight                         | Type: Q8_0 | Shape: [ 256 7200]
Key: output_blocks.8.0.out_layers.0.bias                          | Type: F16 | Shape: [320]
Key: output_blocks.8.0.out_layers.0.weight                        | Type: F16 | Shape: [320]
Key: output_blocks.8.0.out_layers.3.bias                          | Type: F16 | Shape: [320]
Key: output_blocks.8.0.out_layers.3.weight                        | Type: Q8_0 | Shape: [ 256 3600]
Key: output_blocks.8.0.skip_connection.bias                       | Type: F16 | Shape: [320]
Key: output_blocks.8.0.skip_connection.weight                     | Type: Q8_0 | Shape: [256 800]
Key: time_embed.0.bias                                            | Type: F16 | Shape: [1280]
Key: time_embed.0.weight                                          | Type: F16 | Shape: [ 256 1600]
Key: time_embed.2.bias                                            | Type: F16 | Shape: [1280]
Key: time_embed.2.weight                                          | Type: F16 | Shape: [1280 1280]

Total Tensors: 1680